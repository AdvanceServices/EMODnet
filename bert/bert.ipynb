{"cells":[{"cell_type":"markdown","metadata":{"id":"vQYaLueqi8op"},"source":["**First step: Go to the \"runtime\" field in google collab and in \"change runtime type\" select the GPU.**"]},{"cell_type":"markdown","metadata":{"id":"RYptdANk932Q"},"source":["**Connenction to google drive**\n","\n","Click the \"play\" button to run the cell. You will be connected to your personal google drive."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26148,"status":"ok","timestamp":1676899575838,"user":{"displayName":"Melina Loulakaki","userId":"11724484154140628948"},"user_tz":-120},"id":"2N-g7FtHU3WL","outputId":"14587c23-659d-46e9-cc3b-0467bbca934a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["#connects to google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"p6PbC4jL97cm"},"source":["**Set working directory's path**\n","\n","Open the \"file folder\" on the right and navigate into the drive folder in order to find the EMODNET folder.Then by clicking the three dots next to EMODNET folder, copy the path. Delete the existing path in the os.chdir below before \"models/..\" and then paste yours to conclude in something like: os.chdir(r\"/your path/EMODnet/models/bert\")"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2008,"status":"ok","timestamp":1676899577841,"user":{"displayName":"Melina Loulakaki","userId":"11724484154140628948"},"user_tz":-120},"id":"m_nWBArCy5cL"},"outputs":[],"source":["#changes the path with the location of the folder in your drive\n","import os\n","os.chdir(r\"/content/drive/MyDrive/Workspace/Melina_Loulakaki/EMODnet/models/bert\")"]},{"cell_type":"markdown","metadata":{"id":"mtfkDU0RuORq"},"source":["**Required installations**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JQaAAWEpNWcg"},"outputs":[],"source":["#downloads the CUDA 9.2 installer for Ubuntu 16.04 and saves it as a .deb file\n","!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n","#installs the downloaded CUDA 9.2 package\n","!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n","#adds the public key to the system to authenticate the package\n","!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n","#updates the package list\n","!apt-get update\n","#installs CUDA 9.2\n","!apt-get install cuda-9.2"]},{"cell_type":"markdown","metadata":{"id":"X4rS77Tbul5R"},"source":["Pip install commands for installing different versions of PyTorch and its related libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KY2o6-h_Pigj"},"outputs":[],"source":["#installs PyTorch version 1.7.1 with CUDA 9.2 support, torchvision version 0.8.2 with CUDA 9.2 support, and torchaudio version 0.7.2.\n","%pip install torch==1.7.1+cu92 torchvision==0.8.2+cu92 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n","#installs the torchtext library, which provides data processing utilities and popular datasets for natural language processing tasks.\n","%pip install torchtext \n","#installs the torchvision library, which provides datasets, transforms, and models for computer vision tasks.\n","%pip install torchvision \n","#installs the torchaudio library, which provides audio processing utilities and popular datasets for speech and audio-related tasks.\n","%pip install torchaudio  "]},{"cell_type":"markdown","metadata":{"id":"CMw1kuGh3PQr"},"source":["Installs spacy and downloads the english model en_core_web_trf\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"88nvwaHfPvEz"},"outputs":[],"source":["%pip install -U spacy==3.4.2\n","!python -m spacy download en_core_web_trf"]},{"cell_type":"markdown","metadata":{"id":"Ta7eIdTo3T8D"},"source":["Installs the latest version of spaCy with CUDA 9.2 and Transformers support.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dcnddiNlP_gL"},"outputs":[],"source":["%pip install -U spacy[cuda92,transformers]"]},{"cell_type":"markdown","metadata":{"id":"xgS5bvf1vU2j"},"source":["This command installs the CuPy library with support for CUDA 9.2. CuPy is a library that provides NumPy-like arrays for GPU computation, which can greatly accelerate certain types of operations. By installing CuPy with support for CUDA 9.2, this command allows for efficient computation on GPUs that support that version of CUDA."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxzETH3oRvV0"},"outputs":[],"source":["%pip install cupy-cuda92"]},{"cell_type":"markdown","metadata":{"id":"bkd3yiRyvgtS"},"source":["The !export commands set environment variables in the current shell session.\n","\n","CUDA_PATH is set to the path where CUDA 9.2 is installed (/usr/local/cuda-9.2), which is used by other programs to locate the CUDA libraries and binaries.\n","\n","LD_LIBRARY_PATH is a list of directories that the operating system searches when looking for shared libraries. Here, it is set to include the CUDA 9.2 library directory (\\$CUDA_PATH/lib64) so that programs linked against CUDA can find the necessary libraries. The existing value of LD_LIBRARY_PATH is preserved using the $LD_LIBRARY_PATH variable."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TbIXERFZR_VM"},"outputs":[],"source":["!export CUDA_PATH=\"/usr/local/cuda-9.2\"\n","!export LD_LIBRARY_PATH=$CUDA_PATH/lib64:$LD_LIBRARY_PATH"]},{"cell_type":"markdown","metadata":{"id":"ACiRWHMqwGSr"},"source":["The script collapses multi-word tokens into a single word by concatenating the first two words if the second word is only two characters long. The resulting data frames are stored in the variables dftrain, dfdev, and dfeval."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0L14D1WgXWyr"},"outputs":[],"source":["#script in order to fix format from ubiai (it was an error every time that a string has 2 words and the second was smaller or equal than 2 chars e.g \"harbour :\" or \"harbour at\")\n","import pandas as pd #load pandas library for read_csv\n","#reads the three datasets into dftrain, dfdev, dfeval variables as dataframes.\n","dftrain = pd.read_csv(\"data/training_IOBall.tsv\", sep='\\t+', header=None, skiprows=1, engine='python', encoding=\"utf8\")\n","dfdev = pd.read_csv(\"data/development_IOBall.tsv\", sep='\\t+', header=None, skiprows=1, engine='python', encoding=\"utf8\")\n","dfeval = pd.read_csv(\"data/evaluation_IOBall.tsv\", sep='\\t+', header=None, skiprows=1, engine='python', encoding=\"utf8\")\n","\n","def df_collapse(df):\n","  for i in range(len(df[0])):\n","      a=df[0][i].split(\" \")\n","      if(len(a) >= 2):\n","        if(len(a[1])<=2):\n","          df[0][i]=a[0] + a[1]\n","      else:\n","        df[0][i]=df[0][i]\n","  return df\n","\n","dftrain=df_collapse(dftrain)\n","dfdev=df_collapse(dfdev)\n","dfeval=df_collapse(dfeval)\n","\n","#saves the files into .csv in the working directory\n","dftrain.to_csv(\"formatted_data/dftrain.tsv\",index=False,sep=\"\\t\",header=None)\n","dfdev.to_csv(\"formatted_data/dfdev.tsv\",index=False,sep=\"\\t\",header=None)\n","dfeval.to_csv(\"formatted_data/dfeval.tsv\",index=False,sep=\"\\t\",header=None)\n"]},{"cell_type":"markdown","metadata":{"id":"_ex6kPrYwsah"},"source":["**Convert data into .spacy [doc bin file](https://spacy.io/api/docbin)**\n","\n","This is a Python function that takes in two arguments: train_data, which is a list of training examples, and name, which is a string that will be used as the filename when the training data is saved in the desired format."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45998,"status":"ok","timestamp":1676898301915,"user":{"displayName":"Melina Loulakaki","userId":"11724484154140628948"},"user_tz":-120},"id":"S8i9q6cmuORu","outputId":"2e583c0c-8669-42f5-82d3-1538908187b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n","2023-02-20 13:04:17.231921: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-20 13:04:18.486226: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-02-20 13:04:18.486356: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-02-20 13:04:18.486376: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","2023-02-20 13:04:20.467065: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 1 sentences into a document.\u001b[0m\n","\u001b[38;5;3m⚠ To generate better training data, you may want to group sentences\n","into documents with `-n 10`.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n","parser-based sentence segmentation.)\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents): json_data/dftrain.json\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n","2023-02-20 13:04:25.764313: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-20 13:04:27.021970: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-02-20 13:04:27.022119: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-02-20 13:04:27.022144: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","2023-02-20 13:04:28.817521: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 1 sentences into a document.\u001b[0m\n","\u001b[38;5;3m⚠ To generate better training data, you may want to group sentences\n","into documents with `-n 10`.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n","parser-based sentence segmentation.)\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents): json_data/dfdev.json\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n","2023-02-20 13:04:33.213178: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-20 13:04:34.481473: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-02-20 13:04:34.481663: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-02-20 13:04:34.481702: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","2023-02-20 13:04:37.046157: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 1 sentences into a document.\u001b[0m\n","\u001b[38;5;3m⚠ To generate better training data, you may want to group sentences\n","into documents with `-n 10`.\u001b[0m\n","\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n","parser-based sentence segmentation.)\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents): json_data/dfeval.json\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n","2023-02-20 13:04:41.377584: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-20 13:04:42.599057: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-02-20 13:04:42.599188: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-02-20 13:04:42.599212: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","2023-02-20 13:04:44.375828: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","\u001b[38;5;2m✔ Generated output file (473 documents): spacy_data/dftrain.spacy\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n","2023-02-20 13:04:48.104205: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-20 13:04:49.724152: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-02-20 13:04:49.724319: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-02-20 13:04:49.724346: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","2023-02-20 13:04:52.352877: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","\u001b[38;5;2m✔ Generated output file (2 documents): spacy_data/dfdev.spacy\u001b[0m\n","/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n","2023-02-20 13:04:55.969728: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-20 13:04:57.191272: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-02-20 13:04:57.191414: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-02-20 13:04:57.191436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","2023-02-20 13:04:58.959894: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","\u001b[38;5;2m✔ Generated output file (571 documents): spacy_data/dfeval.spacy\u001b[0m\n"]}],"source":["#in order to convert from IOB to JSON\n","!python -m spacy convert formatted_data/dftrain.tsv ./json_data -t json -s -n 1 -c iob #-n 10\n","!python -m spacy convert formatted_data/dfdev.tsv ./json_data -t json -s -n 1 -c iob\n","!python -m spacy convert formatted_data/dfeval.tsv ./json_data -t json -s -n 1 -c iob\n","\n","#in order to convert from json to .spacy\n","!python -m spacy convert json_data/dftrain.json ./spacy_data -t spacy\n","!python -m spacy convert json_data/dfdev.json ./spacy_data -t spacy\n","!python -m spacy convert json_data/dfeval.json ./spacy_data -t spacy"]},{"cell_type":"markdown","metadata":{"id":"iHOPdkfMw3OL"},"source":["**Initialization of the configuration file**\n","\n","Training config files include all settings and hyperparameters for training the pipeline, such as the number of epochs (an \"epoch\" refers to a full iteration over the entire training dataset.. Instead of providing lots of arguments on the command line, "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MVj2UAlVaZHf"},"outputs":[],"source":["# #load locale library. Locale may be a string, or an iterable of two strings (language code and encoding).\n","# import locale\n","# locale.getpreferredencoding = (lambda *args: 'UTF-8') #sets the encoding to UTF-8\n","\n","#base.config configuration file initiallization and config.cfg fill for training\n","!python -m spacy init fill-config config_files/base_config.cfg config_files/config.cfg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"79HzbpZB1Viq"},"outputs":[],"source":["#debugging the config file\n","!python -m spacy debug data config.cfg"]},{"cell_type":"markdown","metadata":{"id":"CLVSZ9YIxFDa"},"source":["**Model Training**\n","\n","In order to train the pipeline uses the train command of spacy."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NWbu8GmqZe9N"},"outputs":[],"source":["#this command is using the spaCy library to train a new language model using the configuration file config.cfg. The training data will be loaded from dftrain.spacy and the development/validation data from dfdev.spacy.\n","#you can set additional command-line options starting with -- that correspond to the config section and value to override. For example, --paths.train ./corpus/train.spacy sets the train value in the [paths] block.\n","!python -m spacy train config_files/config.cfg --output ./ --paths.train ./spacy_data/dftrain.spacy --paths.dev ./spacy_data/dfdev.spacy\n","#after training is complete, the trained model is saved in the working directory as model-best and model-last, use the model-best\n","#if you want to keep the trained model and not overwrite it if you choose to train another one, after training is complete go to the folder of the project in your working directory and rename it "]},{"cell_type":"markdown","metadata":{"id":"TpFjEjUg_Utm"},"source":["**Model's Evaluation**\n","\n","This command is using the spaCy library to evaluate the performance of a trained language model on a validation dataset loaded from the train_eval_full.spacy file. The model being evaluated is the one that performed best during training and was saved as "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vd9P-Fnt0pXt"},"outputs":[],"source":["#evaluation of the model\n","!python -m spacy evaluate model-best spacy_data/dfeval.spacy --gpu-id 0"]},{"cell_type":"markdown","metadata":{"id":"odN27UmM_N2N"},"source":["**Dictionaries load**\n","\n","Created dictionaries for distribution discriptors, life stages, body size and sampling devices are placed in the models' folder as .csv files."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nA32OhK1Q2kd"},"outputs":[],"source":["#read the dictionaries into variables df,df1,df2,df3 as pandas dataframes\n","#read_csv() function imports a CSV file to DataFrame format\n","df=pd.read_csv(\"dictionaries/Distribution_descriptors.csv\",header=None)\n","df1=pd.read_csv(\"dictionaries/Life_stages.csv\",header=None)\n","df2=pd.read_csv(\"dictionaries/Body_size.csv\",header=None)\n","df3=pd.read_csv(\"dictionaries/Sampling_devices.csv\",header=None)\n","\n","#keeps the first column of each dictionary into variables to have the ability to access them later\n","df_distr_descr=df.iloc[:,0]\n","df_life_stages=df1.iloc[:,0]\n","df_body_size=df2.iloc[:,0]\n","df_sampl_devices=df3.iloc[:,0]"]},{"cell_type":"markdown","metadata":{"id":"Ep0_7wR2_EQG"},"source":["**Add dictionaries to the [entity ruler](https://spacy.io/api/entityruler)**\n","\n","In order to improve the model, dictionaries are added in the pipeline with the help of the entity ruler."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EduXjaC8P5Bu"},"outputs":[],"source":["#import tokenizer from spacy and save it in the tokenizer variable\n","from spacy.tokenizer import Tokenizer\n","nlp=spacy.blank(\"en\")\n","tokenizer = nlp.tokenizer\n","\n","#script in order to put the entity_ruler with dictionaries into ner pipeline\n","#entity ruler's patterns(entities) evaluate only if they are not annotaded in training data, so the ”entity_ruler” will only add new entities that match to the patterns only if they don’t overlap with existing entities predicted by the statistical model\n","def entity_ruler(nlp_model,model):\n","    if \"entity_ruler\" not in nlp_model.pipe_names:\n","        ruler=nlp_model.add_pipe(\"entity_ruler\")\n","    else:\n","        ruler=nlp_model.get_pipe(\"entity_ruler\")\n","\n","    #script for adding the desirable patterns of dictionaries' entries into the entity ruler pipe\n","    def dict_func(df,linkdf,label):\n","        patterns=[]\n","        j=0\n","        for i in df:\n","            dict={\"label\": label}\n","            dict[\"pattern\"]=[{\"LOWER\" : str.lower(i)}]\n","            #in order to take the id link of dictionaries's entities if exists, for now it is commented out cause there are not links for all the entities\n","            # dict[\"id\"]=linkdf[[1]][1][j]\n","            patterns.append(dict)\n","            tokens=tokenizer(i)\n","            if len(tokens) == 2:\n","                dict={\"label\": label}\n","                dict[\"pattern\"]=[{\"LOWER\" : str.lower(str(tokens[0]))}, {\"IS_PUNCT\": True}, {\"LOWER\" : str.lower(str(tokens[1]))}]\n","                # dict[\"id\"]=linkdf[[1]][1][j]\n","                patterns.append(dict)\n","            j=j+1\n","        ruler.add_patterns(patterns)\n","    #calls dict func to add the dictionaries\n","    dict_func(df_distr_descr,df,\"DISTRIBUTION_DESCRIPTOR\")\n","    dict_func(df_life_stages,df1,\"LIFE_STAGE\")\n","    dict_func(df_body_size,df2,\"BODY_SIZE\")\n","    dict_func(df_sampl_devices,df3,\"SAMPLING_DEVICE\")\n","\n","    #puts entity ruler into the trained model pipeline\n","    nlp_model.to_disk(model)\n","\n","nlp_full=spacy.load(\"model-best\")#loads the trained model\n","entity_ruler(nlp_full,\"model-best_ruler\")#calls the entity_ruler script and saves the model with entity ruler in the name of model-best_ruler\n"]},{"cell_type":"markdown","metadata":{"id":"jt9JQCSP-9T2"},"source":["**Model Evaluation after dictionaries addition**\n","\n","This command is using the spaCy library to evaluate the performance of a trained language model on a validation dataset loaded from the train_eval_full.spacy file. The model being evaluated was saved as "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ILht4QohuORw"},"outputs":[],"source":["#evaluation of the model after dictionaries addition\n","!python -m spacy evaluate model-best_ruler ./spacy_data/dfeval.spacy --gpu-id 0"]},{"cell_type":"markdown","metadata":{"id":"m8kD2txz_Asm"},"source":["**Model's Performance Testing**\n","\n","In this section the trained model is loaded as an nlp variable and tested in an example text. The output result is the extracted entities founded by the model in the text."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7c74p44Zv9Rn"},"outputs":[],"source":["import spacy\n","from spacy import displacy\n","\n","#load trained model\n","nlp_full=spacy.load(\"model-best_ruler\") \n","#put the text you want to extract entities into the nlp_full(\" \"), it will be saved to the doc variable\n","doc=nlp_full(\"Atherinids are small marine, estuarine and freshwater fishes not exceeding 120 mm SL (a soon to be described species of Craterocephalus may reach 300 mm SL), occurring predominantly in the Old World, with only Alepidomus evermanni (freshwa\u0002ters of Cuba) and two marine species, Atheri\u0002nomorus stipes and Hypoatherina harringtonensis (predominantly in the shore waters of the Caribbean) known from the New World. I\")\n","\n","print([(ent.text, ent.label_ ,ent.start_char, ent.end_char, ent.ent_id_) for ent in doc.ents]) #prints the text, the entity-label, the start char, the end char and an id link of extracted entities, if it exists\n","print(\"\\n\")\n","\n","displacy.render(doc, style=\"ent\") #call displacy.render in order to visualise the resulted entities"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"94e7e65be05b4ed6ba93e18d7d6886bab5ac9fc35747516c0d44d14f8ddf2d8d"}}},"nbformat":4,"nbformat_minor":0}
