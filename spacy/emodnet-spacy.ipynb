{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.lang.en import English\n",
    "\n",
    "#nlp=English()\n",
    "#arxikopoihsh tou nlp kai entity ruler\n",
    "nlp=spacy.blank(\"en\")\n",
    "ruler=nlp.add_pipe(\"entity_ruler\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in order to convert ubiai IOB format into spacy input for training\n",
    "#gia na to diavasei swsta esvhsa thn prwth grammh kai evala no header\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train_all = pd.read_csv(\"training_IOBall.tsv\", sep='\\t+', header=None, engine='python') #skiprows=1,\n",
    "dev_all = pd.read_csv(\"development_IOBall.tsv\", sep='\\t+', header=None, engine='python')\n",
    "eval_all = pd.read_csv(\"evaluation_IOBall.tsv\", sep='\\t+', header=None, engine='python')\n",
    "\n",
    "# print(train_all)\n",
    "def iob_to_spacy(df):\n",
    "    words = df[0]\n",
    "    tags = df[1]\n",
    "    total_words = len(words)\n",
    "    data = []\n",
    "    data_i = 0\n",
    "    i = 0\n",
    "\n",
    "    sentence = \"\"\n",
    "    sentence_len = 0\n",
    "    sentence_entities = []\n",
    "    for word in words:\n",
    "        dot_index = word.find('.')\n",
    "        if (dot_index != -1):\n",
    "            # vrethike sth thesh dot_index\n",
    "            if (dot_index == len(word)-1):\n",
    "                # einai telefteo gramma\n",
    "                # prepei na checkarw to 1o gramma sto epomeno word\n",
    "                if (total_words-1 > i):\n",
    "                    # uparxei to epomeno word\n",
    "                    # elegxw to 1o gramma an einai kefaleo\n",
    "                    if (words[i+1][0].isupper()):\n",
    "                        sentence += word\n",
    "                        if (tags[i] != 'O'):\n",
    "                            entity = (sentence_len, len(sentence), tags[i])\n",
    "                            sentence_entities.append(entity)\n",
    "                        sentence_len = len(sentence)\n",
    "                        new_val = (sentence, {\"entities\": sentence_entities})\n",
    "                        data.append(new_val)\n",
    "                        sentence = \"\"\n",
    "                        sentence_len = 0\n",
    "                        sentence_entities = []\n",
    "                    else:\n",
    "                        sentence += word + \" \"\n",
    "                        if (tags[i] != 'O'):\n",
    "                            entity = (sentence_len, len(sentence), tags[i])\n",
    "                            sentence_entities.append(entity)\n",
    "                        sentence_len = len(sentence)\n",
    "        else:\n",
    "            sentence += word + \" \"\n",
    "            if (tags[i] != 'O'):\n",
    "                entity = (sentence_len, len(sentence), tags[i])\n",
    "                sentence_entities.append(entity)\n",
    "            sentence_len = len(sentence)\n",
    "        i += 1\n",
    "    for sent in data:\n",
    "        entities = sent[1]['entities']\n",
    "        new_entities = []\n",
    "        entity_start = 0\n",
    "        entity_end = 0\n",
    "        entity_type = \"\"\n",
    "        for entity in entities:\n",
    "            if entity[2][0] == \"B\":\n",
    "                if entity_end != 0:\n",
    "                    new_entity = (entity_start, entity_end, entity_type)\n",
    "                    new_entities.append(new_entity)\n",
    "                entity_start = entity[0]\n",
    "                entity_end = entity[1]\n",
    "                entity_type = entity[2]\n",
    "            else:\n",
    "                entity_end = entity[1]\n",
    "        if entity_end != 0:\n",
    "            new_entity = (entity_start, entity_end, entity_type)\n",
    "            new_entities.append(new_entity)\n",
    "            sent[1]['entities']=new_entities\n",
    "\n",
    "    for sent in data:\n",
    "        entity_start = 0\n",
    "        entity_end = 0\n",
    "        entity_type = \"\"\n",
    "        new_entities=[]\n",
    "        for entity in sent[1]['entities']:\n",
    "            entity_start = entity[0]\n",
    "            entity_end = entity[1]\n",
    "            entity_type = entity[2]\n",
    "            entity_type=re.sub(r'.', '', entity_type , count = 2)\n",
    "            new_entity = (entity_start, entity_end, entity_type)\n",
    "            new_entities.append(new_entity)\n",
    "            sent[1]['entities']=new_entities\n",
    "    return data\n",
    "\n",
    "train_fulltext=iob_to_spacy(train_all)\n",
    "dev_fulltext=iob_to_spacy(dev_all)\n",
    "eval_fulltext=iob_to_spacy(eval_all)\n",
    "\n",
    "\n",
    "# print(train_fulltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"dictionaries-annot\\Distribution_descriptors.csv\",header=None)\n",
    "df1=pd.read_csv(\"dictionaries-annot\\Life_stages.csv\",header=None)\n",
    "df2=pd.read_csv(\"dictionaries-annot\\Body_size.csv\",header=None)\n",
    "df3=pd.read_csv(\"dictionaries-annot\\Sampling_devices.csv\",header=None,encoding='cp1252')\n",
    "\n",
    "df_distr_descr=df.iloc[:,0]\n",
    "df_life_stages=df1.iloc[:,0]\n",
    "df_body_size=df2.iloc[:,0]\n",
    "df_biol_descr=df3.iloc[:,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import spacy.cli\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BODY_SIZE', 'DISTRIBUTION_DESCRIPTOR ', 'LIFE_STAGE', 'SAMPLING_DEVICE')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in order to create training data,custom ner model\n",
    "\n",
    "if 'ner' not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe('ner')\n",
    "    nlp.add_pipe(\"ner\", last=True)\n",
    "else:\n",
    "    ner = nlp.get_pipe('ner')\n",
    "\n",
    "# ner.add_label(\"Distribution_descriptor\")\n",
    "# ner.add_label(\"Life_stage\")\n",
    "# ner.add_label(\"Body_size\")\n",
    "# ner.add_label(\"Sampling_device\")\n",
    "ner.add_label(\"DISTRIBUTION_DESCRIPTOR \")\n",
    "ner.add_label(\"LIFE_STAGE\")\n",
    "ner.add_label(\"BODY_SIZE\")\n",
    "ner.add_label(\"SAMPLING_DEVICE\")\n",
    "ner.labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 814/814 [00:00<00:00, 7903.16it/s]\n",
      "100%|██████████| 455/455 [00:00<00:00, 6066.14it/s]\n",
      "100%|██████████| 707/707 [00:00<00:00, 7364.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from spacy.util import filter_spans\n",
    "\n",
    "def training_data_format(train_data,name):\n",
    "    doc_bin = DocBin()\n",
    "    for training_example in tqdm(train_data): \n",
    "        text = training_example[0]\n",
    "        # print(text)\n",
    "        labels = training_example[1]['entities']\n",
    "        # print(training_example[1])\n",
    "        doc = nlp.make_doc(text) \n",
    "        ents = []\n",
    "        for start, end, label in labels:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print(\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        filtered_ents = filter_spans(ents)\n",
    "        doc.ents = filtered_ents \n",
    "        doc_bin.add(doc)\n",
    "    \n",
    "    return(doc_bin.to_disk(\"train_\" + name + \".spacy\"))\n",
    "\n",
    "\n",
    "training_data_format(train_fulltext,\"train_full\")\n",
    "training_data_format(dev_fulltext,\"dev_full\")\n",
    "training_data_format(eval_fulltext,\"eval_full\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Auto-filled config with all values\n",
      "✔ Saved config\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "#configuration file initiallization\n",
    "!python -m spacy init fill-config base_config.cfg config.cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ Saving to output directory: .\n",
      "ℹ Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "✔ Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "ℹ Pipeline: ['tok2vec', 'ner']\n",
      "ℹ Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     35.00    0.00    0.00    0.00    0.00\n",
      "  1     200         36.79   1567.91   26.62   24.18   29.60    0.27\n",
      "  2     400         68.53   1115.46   30.84   34.31   28.00    0.31\n",
      "  4     600         53.19   1155.08   45.43   35.98   61.60    0.45\n",
      "  6     800        229.58   1081.01   34.62   33.33   36.00    0.35\n",
      "  9    1000        100.33    863.77   21.83   15.02   40.00    0.22\n",
      " 12    1200        233.04    804.37   37.66   39.47   36.00    0.38\n",
      " 16    1400        183.36    720.22   35.63   36.07   35.20    0.36\n",
      " 21    1600        178.14    606.85   37.82   34.67   41.60    0.38\n",
      " 28    1800        317.75    577.24   29.43   23.56   39.20    0.29\n",
      " 35    2000        130.33    467.33   34.84   30.86   40.00    0.35\n",
      " 45    2200        160.70    517.96   33.22   28.82   39.20    0.33\n",
      "✔ Saved pipeline to output directory\n",
      "model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-30 10:07:05,156] [INFO] Set up nlp object from config\n",
      "[2023-01-30 10:07:05,166] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2023-01-30 10:07:05,170] [INFO] Created vocabulary\n",
      "[2023-01-30 10:07:06,793] [INFO] Added vectors: en_core_web_lg\n",
      "[2023-01-30 10:07:08,121] [INFO] Finished initializing nlp object\n",
      "[2023-01-30 10:07:08,813] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' #for error fixing\n",
    "!python -m spacy train config.cfg --output ./ --paths.train ./train_train_full.spacy --paths.dev ./train_eval_full.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('marine', 'DISTRIBUTION_DESCRIPTOR', 21, 27, ''), ('estuarine', 'DISTRIBUTION_DESCRIPTOR', 29, 38, ''), ('freshwater', 'DISTRIBUTION_DESCRIPTOR', 43, 53, ''), ('120 mm SL', 'BODY_SIZE', 75, 84, ''), ('300 mm SL', 'BODY_SIZE', 146, 155, ''), ('Alepidomus evermanni', 'DISTRIBUTION_DESCRIPTOR', 210, 230, ''), ('marine', 'DISTRIBUTION_DESCRIPTOR', 262, 268, ''), ('shore waters', 'DISTRIBUTION_DESCRIPTOR', 355, 367, '')]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Atherinids are small \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    marine\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISTRIBUTION_DESCRIPTOR</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    estuarine\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISTRIBUTION_DESCRIPTOR</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    freshwater\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISTRIBUTION_DESCRIPTOR</span>\n",
       "</mark>\n",
       " fishes not exceeding \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    120 mm SL\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">BODY_SIZE</span>\n",
       "</mark>\n",
       " (a soon to be described species of Craterocephalus may reach \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    300 mm SL\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">BODY_SIZE</span>\n",
       "</mark>\n",
       "), occurring predominantly in the Old World, with only \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Alepidomus evermanni\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISTRIBUTION_DESCRIPTOR</span>\n",
       "</mark>\n",
       " (freshwa\u0002ters of Cuba) and two \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    marine\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISTRIBUTION_DESCRIPTOR</span>\n",
       "</mark>\n",
       " species, Atheri\u0002nomorus stipes and Hypoatherina harringtonensis (predominantly in the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    shore waters\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DISTRIBUTION_DESCRIPTOR</span>\n",
       "</mark>\n",
       " of the Caribbean) known from the New World. I</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "nlp_full=spacy.load(\"model-best_fulldev-eval\")\n",
    "doc=nlp_full(\"Atherinids are small marine, estuarine and freshwater fishes not exceeding 120 mm SL (a soon to be described species of Craterocephalus may reach 300 mm SL), occurring predominantly in the Old World, with only Alepidomus evermanni (freshwa\u0002ters of Cuba) and two marine species, Atheri\u0002nomorus stipes and Hypoatherina harringtonensis (predominantly in the shore waters of the Caribbean) known from the New World. I\")\n",
    "\n",
    "print([(ent.text, ent.label_ ,ent.start_char, ent.end_char, ent.ent_id_) for ent in doc.ents])\n",
    "print(\"\\n\")\n",
    "\n",
    "displacy.render(doc, style=\"ent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "tokenizer = nlp.tokenizer\n",
    "\n",
    "#in order to put the entity_ruler into nlp_ner pipeline\n",
    "#entity ruler's patterns(entities) evaluate only if they are not annotaded in training data, so the ”entity_ruler” will only add new entities that match to the patterns only if they don’t overlap with existing entities predicted by the statistical model\n",
    "#QUEST PWS THA EPISTREFOUME TO LINK AN EINAI APO TRAINING ?PROS TO PARON TO EPISTREFOUME APO TO ENTITY RULER mono se auta pou den exoun oristei apo training loipon\n",
    "def entity_ruler(nlp_model,model):\n",
    "    #nlp_ner_corpus2.remove_pipe(\"entity_ruler\")\n",
    "    if \"entity_ruler\" not in nlp_model.pipe_names:\n",
    "        ruler=nlp_model.add_pipe(\"entity_ruler\")\n",
    "    else:\n",
    "        ruler=nlp_model.get_pipe(\"entity_ruler\")\n",
    "\n",
    "    #GIA PATTERNS\n",
    "    def dict_func(df,linkdf,label):\n",
    "        patterns=[]\n",
    "        j=0\n",
    "        for i in df:\n",
    "            dict={\"label\": label}\n",
    "            dict[\"pattern\"]=[{\"LOWER\" : str.lower(i)}]\n",
    "            dict[\"id\"]=linkdf[[1]][1][j]\n",
    "            patterns.append(dict)\n",
    "            tokens=tokenizer(i)\n",
    "            if len(tokens) == 2:\n",
    "                dict={\"label\": label}\n",
    "                dict[\"pattern\"]=[{\"LOWER\" : str.lower(str(tokens[0]))}, {\"IS_PUNCT\": True}, {\"LOWER\" : str.lower(str(tokens[1]))}]\n",
    "                dict[\"id\"]=linkdf[[1]][1][j]\n",
    "                patterns.append(dict)\n",
    "            j=j+1\n",
    "        ruler.add_patterns(patterns)\n",
    "\n",
    "    dict_func(df_distr_descr,df,\"Distribution_descriptor\")\n",
    "    dict_func(df_life_stages,df1,\"Life_stage\")\n",
    "    dict_func(df_body_size,df2,\"Body_size\")\n",
    "    #dict_func(df_biol_descr,\"Biological Descriptor\")\n",
    "\n",
    "    #in order to put entity ruler into the trained model pipeline\n",
    "    nlp_model.to_disk(model)\n",
    "\n",
    "nlp_roberta=spacy.load(\"model-roberta_dev\")\n",
    "entity_ruler(nlp_roberta,\"model-roberta_dev_ruler\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ Using CPU\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK     100.00\n",
      "NER P   27.08 \n",
      "NER R   18.40 \n",
      "NER F   21.91 \n",
      "SPEED   4928  \n",
      "\n",
      "\u001b[1m\n",
      "=============================== NER (per type) ===============================\u001b[0m\n",
      "\n",
      "                              P       R       F\n",
      "BODY_SIZE                  9.62    6.10    7.46\n",
      "DISTRIBUTION_DESCRIPTOR   38.64   26.56   31.48\n",
      "SAMPLING_DEVICE            0.00    0.00    0.00\n",
      "LIFE_STAGE                 0.00    0.00    0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python -m spacy evaluate model-best_fulldev-eval/ train_dev_full.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_ner_corpusIOB_dev=spacy.load(\"model-corpusIOB_dev\")\n",
    "nlp_ner_corpusIOB_dev.pipe_names\n",
    "\n",
    "\n",
    "nlp_ner_corpusIOB_dev_ruler=spacy.load(\"model-corpusIOB_dev_ruler\")\n",
    "nlp_ner_corpusIOB_dev_ruler.pipe_names\n",
    "\n",
    "paper2=nlp_ner_corpusIOB_dev(\"Most marine fish and invertebrate species produce free and small early-stages which are part of the plankton. These incompletely developed individuals are highly vulnerable to unsuitable conditions like starvation and environmental variability, and it was early recognized that survival during these stages often regulates recruitment and adult population size (Cowan and Shaw, 2002, Pineda et al., 2007). Recruitment theories have thus focused on the environmental modulation of larval survival, and they generally assume that while spawning occurs within relatively fixed time-frames along the year cycle, hydrographic conditions and plankton production show higher inter-annual variability.\")\n",
    "doc=nlp_ner_corpusIOB_dev_ruler(\"Most marine fish and invertebrate species produce free and small early-stages which are part of the plankton. These incompletely developed individuals are highly vulnerable to unsuitable conditions like starvation and environmental variability, and it was early recognized that survival during these stages often regulates recruitment and adult population size (Cowan and Shaw, 2002, Pineda et al., 2007). Recruitment theories have thus focused on the environmental modulation of larval survival, and they generally assume that while spawning occurs within relatively fixed time-frames along the year cycle, hydrographic conditions and plankton production show higher inter-annual variability.\")\n",
    "\n",
    "print([(ent.text, ent.label_ ,ent.start_char, ent.end_char, ent.ent_id_) for ent in doc.ents])\n",
    "print(\"\\n\")\n",
    "print([(ent.text, ent.label_ ,ent.start_char, ent.end_char, ent.ent_id_) for ent in paper2.ents])\n",
    "\n",
    "displacy.render(doc, style=\"ent\" )\n",
    "displacy.render(paper2, style=\"ent\" )\n",
    "nlp_ner_corpusIOB_dev_ruler.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "combined_model=spacy.load(\"combined_IOBspacy_roberta_dev_ruler\")\n",
    "combined_model.to_disk(\"combined_IOBspacy_roberta_dev_ruler\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining 2 ner from trained models (roberta and spacy model)\n",
    "\n",
    "# nlp_roberta=spacy.load(\"model-roberta_dev_ruler\")\n",
    "# nlp_roberta.rename_pipe(\"ner\", \"ner_roberta\")\n",
    "# nlp_roberta.to_disk(\"model-roberta_dev_ruler\")\n",
    "\n",
    "nlp1 = spacy.load(\"model-corpusIOB_dev_ruler\")\n",
    "\n",
    "# Load the second model\n",
    "nlp2 = spacy.load(\"model-roberta_dev_ruler\")\n",
    "# Add the components from the second model to the first\n",
    "for name, component in nlp2.pipeline:\n",
    "    if name  not in nlp1.pipe_names:\n",
    "        nlp1.add_pipe(name=name,source=nlp2,factory_name=name)\n",
    "    \n",
    "nlp1.to_disk(\"combined_IOBspacy_roberta_dev_ruler\")\n",
    "\n",
    "nlp1=spacy.load(\"combined_IOBspacy_roberta_dev_ruler\")\n",
    "doc = nlp1(\"Most marine fish and invertebrate species produce free and small early-stages which are part of the plankton. These incompletely developed individuals are highly vulnerable to unsuitable conditions like starvation and environmental variability, and it was early recognized that survival during these stages often regulates recruitment and adult population size (Cowan and Shaw, 2002, Pineda et al., 2007). Recruitment theories have thus focused on the environmental modulation of larval survival, and they generally assume that while spawning occurs within relatively fixed time-frames along the year cycle, hydrographic conditions and plankton production show higher inter-annual variability.\")\n",
    "\n",
    "displacy.render(doc, style=\"ent\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94e7e65be05b4ed6ba93e18d7d6886bab5ac9fc35747516c0d44d14f8ddf2d8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
