{"cells":[{"attachments":{},"cell_type":"markdown","id":"6951a7b4","metadata":{},"source":["Required installations"]},{"cell_type":"code","execution_count":null,"id":"1657ccc8-b9dd-46e7-a08f-b9176ea274ba","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28952,"status":"ok","timestamp":1674206561931,"user":{"displayName":"Melina Loulakaki","userId":"11724484154140628948"},"user_tz":-120},"id":"1657ccc8-b9dd-46e7-a08f-b9176ea274ba","outputId":"f642e93c-f47b-449f-ea02-2f4676d34231"},"outputs":[],"source":["%pip install transformers\n","%pip install torch\n","%pip install torchvision\n"]},{"cell_type":"code","execution_count":null,"id":"438f352b-1664-4219-b257-855919d467fa","metadata":{"id":"438f352b-1664-4219-b257-855919d467fa"},"outputs":[],"source":["import pandas as pd\n","import torch \n","import numpy as np\n","from transformers import BertTokenizerFast, BertForTokenClassification\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from torch.optim import SGD"]},{"cell_type":"code","execution_count":null,"id":"9352d7af","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":286,"status":"ok","timestamp":1674217871942,"user":{"displayName":"Melina Loulakaki","userId":"11724484154140628948"},"user_tz":-120},"id":"9352d7af","outputId":"2fb8f993-c85c-40cc-de01-6dc7eaf2fdab"},"outputs":[],"source":["# just put the path of the annotated data .tsv here with header \"text  labels\"\n","\n","import re\n","train = pd.read_table('training_IOBall.tsv', keep_default_na=False)\n","dev = pd.read_table('development_IOBall.tsv', keep_default_na=False)\n","evaluate = pd.read_table(\"evaluation_IOBall.tsv\",  keep_default_na=False)\n","\n","train = train[train.apply(lambda x: x.str.strip().str.len().sum(), axis=1) != 0] #to remove empty rows,empty rows containes only a tab in this situation\n","dev = dev[dev.apply(lambda x: x.str.strip().str.len().sum(), axis=1) != 0] #to remove empty rows,empty rows containes only a tab in this situation\n","evaluate = evaluate[evaluate.apply(lambda x: x.str.strip().str.len().sum(), axis=1) != 0] #to remove empty rows,empty rows containes only a tab in this situation\n","\n"]},{"cell_type":"code","execution_count":null,"id":"2727c39e","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1716},"executionInfo":{"elapsed":6065,"status":"ok","timestamp":1674217892712,"user":{"displayName":"Melina Loulakaki","userId":"11724484154140628948"},"user_tz":-120},"id":"2727c39e","outputId":"54f75958-564c-44c4-a8a8-cccfd65e8ff6"},"outputs":[],"source":["#script in order to convert IOB word format into IOB sentence\n","import re\n","def IOBword_to_sent(df,name):\n","    name1=pd.DataFrame()\n","    data=df.iloc\n","    sent=\"\"\n","    labels=\"\"\n","    patterns=[]\n","    for i in range(len(data[:,0])-1):\n","        sent=sent + \" \" + data[i,0]\n","        labels=labels + \" \" + str(data[i,1])\n","        # if((str(data[i,0]) == \".\") & str((data[i+1,0][0])).isupper()):\n","        # print(str((data[i+1,0])))\n","        # print(i)\n","        if(len(re.findall(r\"\\w*\\.\", str(data[i,0]))) & str((data[i+1,0][0])).isupper()):\n","            if(len(sent) > 512):  #because bert have limit 512 char per sequence\n","                print(\"wrong length\")\n","                sent=\"\"\n","                labels=\"\"\n","            else:\n","                text_label={'text': sent, 'labels': labels}\n","                sent=\"\"\n","                labels=\"\"\n","                patterns.append(text_label)\n","    name1 = pd.DataFrame(patterns)\n","    return name1\n","    \n","df_train=IOBword_to_sent(train,\"df_train\")\n","df_eval=IOBword_to_sent(evaluate,\"df_eval\")\n","df_dev=IOBword_to_sent(dev,\"df_dev\")\n","# display(df_dev)\n","# df_train.to_csv(\"C:/Users/melina/Desktop/EMODnet/NER_BERT/train.tsv\",index=False,sep=\"\\t\")\n","# df_eval.to_csv(\"C:/Users/melina/Desktop/EMODnet/NER_BERT/eval.tsv\", index=False,sep=\"\\t\")\n","# df_dev.to_csv(\"C:/Users/melina/Desktop/EMODnet/NER_BERT/dev.tsv\",index=False,sep=\"\\t\")\n","\n","dfall=pd.concat([df_train, df_dev.iloc[1:], df_eval.iloc[1:]], axis=0)\n","dfall"]},{"cell_type":"markdown","id":"c2b1bd34-8843-4706-baa5-201f31245183","metadata":{"id":"c2b1bd34-8843-4706-baa5-201f31245183"},"source":["# Initialize Tokenizer"]},{"cell_type":"code","execution_count":null,"id":"d41be369-ee57-4949-aeb8-7960746d2aea","metadata":{"executionInfo":{"elapsed":713,"status":"ok","timestamp":1674217916083,"user":{"displayName":"Melina Loulakaki","userId":"11724484154140628948"},"user_tz":-120},"id":"d41be369-ee57-4949-aeb8-7960746d2aea"},"outputs":[],"source":["tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"]},{"cell_type":"markdown","id":"0e3439c2-580e-4972-8603-3a00bc3be62d","metadata":{"id":"0e3439c2-580e-4972-8603-3a00bc3be62d"},"source":["# Create Dataset Class "]},{"cell_type":"code","execution_count":null,"id":"ac7f0682-ea50-4aeb-bcd3-9230df735554","metadata":{"executionInfo":{"elapsed":278,"status":"ok","timestamp":1674217920113,"user":{"displayName":"Melina Loulakaki","userId":"11724484154140628948"},"user_tz":-120},"id":"ac7f0682-ea50-4aeb-bcd3-9230df735554"},"outputs":[],"source":["label_all_tokens = False\n","\n","def align_label(texts, labels):\n","    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n","\n","    word_ids = tokenized_inputs.word_ids()\n","\n","    previous_word_idx = None\n","    label_ids = []\n","\n","    for word_idx in word_ids:\n","\n","        if word_idx is None:\n","            label_ids.append(-100)\n","\n","        elif word_idx != previous_word_idx:\n","            try:\n","                label_ids.append(labels_to_ids[labels[word_idx]])\n","            except:\n","                label_ids.append(-100)\n","        else:\n","            try:\n","                label_ids.append(labels_to_ids[labels[word_idx]] if label_all_tokens else -100)\n","            except:\n","                label_ids.append(-100)\n","        previous_word_idx = word_idx\n","\n","    return label_ids\n","\n","class DataSequence(torch.utils.data.Dataset):\n","\n","    def __init__(self, df):\n","\n","        lb = [i.split() for i in df['labels'].values.tolist()]\n","        txt = df['text'].values.tolist()\n","        self.texts = [tokenizer(str(i),\n","                               padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\") for i in txt]\n","        self.labels = [align_label(i,j) for i,j in zip(txt, lb)]\n","\n","    def __len__(self):\n","\n","        return len(self.labels)\n","\n","    def get_batch_data(self, idx):\n","\n","        return self.texts[idx]\n","\n","    def get_batch_labels(self, idx):\n","\n","        return torch.LongTensor(self.labels[idx])\n","\n","    def __getitem__(self, idx):\n","\n","        batch_data = self.get_batch_data(idx)\n","        batch_labels = self.get_batch_labels(idx)\n","\n","        return batch_data, batch_labels"]},{"cell_type":"markdown","id":"496b3cb5-24c8-4c1b-8382-7c4d0f2339a4","metadata":{"id":"496b3cb5-24c8-4c1b-8382-7c4d0f2339a4"},"source":["# Split Data and Define Unique Labels"]},{"cell_type":"code","execution_count":null,"id":"6599961c-1cda-47bf-8c82-a1f9ebc94a95","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":459},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1674217924111,"user":{"displayName":"Melina Loulakaki","userId":"11724484154140628948"},"user_tz":-120},"id":"6599961c-1cda-47bf-8c82-a1f9ebc94a95","outputId":"0fef4f5e-719a-44ef-959e-923499cf1e17"},"outputs":[],"source":["a=pd.DataFrame()\n","labels=\"\"\n","a['labels']=pd.concat([df_train['labels'],df_eval['labels'],df_dev['labels']])\n","\n","labels = [i.split() for i in a['labels'].values.tolist()]\n","unique_labels = set()\n","\n","for lb in labels:\n","        [unique_labels.add(i) for i in lb if i not in unique_labels]\n","labels_to_ids = {k: v for v, k in enumerate(unique_labels)}\n","ids_to_labels = {v: k for v, k in enumerate(unique_labels)}\n","\n","print(labels_to_ids)\n","print(ids_to_labels)\n","\n","# df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42),\n","#                             [int(.8 * len(df)), int(.9 * len(df))])\n","df_train=df_train\n","df_val=df_dev\n","df_test=df_eval\n"]},{"cell_type":"markdown","id":"d54b96c5-6875-4990-9248-5d6ad5b053e9","metadata":{"id":"d54b96c5-6875-4990-9248-5d6ad5b053e9"},"source":["# Build Model"]},{"cell_type":"code","execution_count":null,"id":"13ebfa5e-c91a-4967-b0cc-23e314c32348","metadata":{"executionInfo":{"elapsed":563,"status":"ok","timestamp":1674217939392,"user":{"displayName":"Melina Loulakaki","userId":"11724484154140628948"},"user_tz":-120},"id":"13ebfa5e-c91a-4967-b0cc-23e314c32348"},"outputs":[],"source":["class BertModel(torch.nn.Module):\n","\n","    def __init__(self):\n","\n","        super(BertModel, self).__init__()\n","\n","        self.bert = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(unique_labels))\n","\n","    def forward(self, input_id, mask, label):\n","\n","        output = self.bert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)\n","\n","        return output"]},{"cell_type":"markdown","id":"c3a48d06-d343-449b-829d-2bcad4b2af52","metadata":{"id":"c3a48d06-d343-449b-829d-2bcad4b2af52"},"source":["# Model Training"]},{"cell_type":"code","execution_count":null,"id":"291bfdad-2df3-4de3-954d-b7e7a9a1b253","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":850,"referenced_widgets":["ec294d37d6474e849d707ab4d6a366b2","a7ce5cf15868435a839a852aa712cfc0","b724bc96afae4aefbb7402ff4f393e66","fbb4d7b182b64cfb9f0dcb011e15c42e","9c62a3ecb7ce467c950d677eee83d88a","7c6c693f9a814166afe11e6ded2fb72c","832510fef8f04cd08eb3ae8af0676b79","b34bdaf49c134d6596f6e6c53c612446","54d31286f3a0492985f32ded812ebaaa","ad05041418fc4162a6702edd9a1b1b52","2c10625508cf400cb355164e767a7c08"]},"id":"291bfdad-2df3-4de3-954d-b7e7a9a1b253","outputId":"6b920860-ea80-4b45-c641-4005bd8722fa"},"outputs":[],"source":["def train_loop(model, df_train, df_val):\n","\n","    train_dataset = DataSequence(df_train)\n","    val_dataset = DataSequence(df_val)\n","    print(train_dataset)\n","    train_dataloader = DataLoader(train_dataset, num_workers=4, batch_size=BATCH_SIZE, shuffle=True)\n","    val_dataloader = DataLoader(val_dataset, num_workers=4, batch_size=BATCH_SIZE)\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    optimizer = SGD(model.parameters(), lr=LEARNING_RATE)\n","\n","    if use_cuda:\n","        model = model.cuda()\n","\n","    best_acc = 0\n","    best_loss = 1000\n","\n","    for epoch_num in range(EPOCHS):\n","\n","        total_acc_train = 0\n","        total_loss_train = 0\n","\n","        model.train()\n","\n","        for train_data, train_label in tqdm(train_dataloader):\n","\n","            train_label = train_label.to(device)\n","            mask = train_data['attention_mask'].squeeze(1).to(device)\n","            input_id = train_data['input_ids'].squeeze(1).to(device)\n","\n","            optimizer.zero_grad()\n","            loss, logits = model(input_id, mask, train_label)\n","\n","            for i in range(logits.shape[0]):\n","\n","              logits_clean = logits[i][train_label[i] != -100]\n","              label_clean = train_label[i][train_label[i] != -100]\n","\n","              predictions = logits_clean.argmax(dim=1)\n","              acc = (predictions == label_clean).float().mean()\n","              total_acc_train += acc\n","              total_loss_train += loss.item()\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","        model.eval()\n","\n","        total_acc_val = 0\n","        total_loss_val = 0\n","\n","        for val_data, val_label in val_dataloader:\n","\n","            val_label = val_label.to(device)\n","            mask = val_data['attention_mask'].squeeze(1).to(device)\n","            input_id = val_data['input_ids'].squeeze(1).to(device)\n","\n","            loss, logits = model(input_id, mask, val_label)\n","\n","            for i in range(logits.shape[0]):\n","\n","              logits_clean = logits[i][val_label[i] != -100]\n","              label_clean = val_label[i][val_label[i] != -100]\n","\n","              predictions = logits_clean.argmax(dim=1)\n","              acc = (predictions == label_clean).float().mean()\n","              total_acc_val += acc\n","              total_loss_val += loss.item()\n","\n","        val_accuracy = total_acc_val / len(df_val)\n","        val_loss = total_loss_val / len(df_val)\n","\n","        print(\n","            f'Epochs: {epoch_num + 1} | Loss: {total_loss_train / len(df_train): .3f} | Accuracy: {total_acc_train / len(df_train): .3f} | Val_Loss: {total_loss_val / len(df_val): .3f} | Accuracy: {total_acc_val / len(df_val): .3f}')\n","\n","LEARNING_RATE = 5e-3\n","EPOCHS = 20\n","BATCH_SIZE = 2\n","\n","model = BertModel()\n","train_loop(model, df_train, df_val)"]},{"cell_type":"markdown","id":"69e1af60-33c3-497e-984f-0094f9bc3a4f","metadata":{"id":"69e1af60-33c3-497e-984f-0094f9bc3a4f"},"source":["# Evaluate Model"]},{"cell_type":"code","execution_count":null,"id":"04295796-7033-4bdf-849f-95e030fc94aa","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"04295796-7033-4bdf-849f-95e030fc94aa","outputId":"699840c6-1cf9-410f-95c4-b2c3efb331a9"},"outputs":[],"source":["def evaluate(model, df_test):\n","\n","    test_dataset = DataSequence(df_test)\n","\n","    test_dataloader = DataLoader(test_dataset, num_workers=4, batch_size=1)\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    if use_cuda:\n","        model = model.cuda()\n","\n","    total_acc_test = 0.0\n","\n","    for test_data, test_label in test_dataloader:\n","\n","            test_label = test_label.to(device)\n","            mask = test_data['attention_mask'].squeeze(1).to(device)\n","\n","            input_id = test_data['input_ids'].squeeze(1).to(device)\n","\n","            loss, logits = model(input_id, mask, test_label)\n","\n","            for i in range(logits.shape[0]):\n","\n","              logits_clean = logits[i][test_label[i] != -100]\n","              label_clean = test_label[i][test_label[i] != -100]\n","\n","              predictions = logits_clean.argmax(dim=1)\n","              acc = (predictions == label_clean).float().mean()\n","              total_acc_test += acc\n","\n","    val_accuracy = total_acc_test / len(df_test)\n","    print(f'Test Accuracy: {total_acc_test / len(df_test): .3f}')\n","\n","\n","evaluate(model, df_test)"]},{"cell_type":"markdown","id":"12edbaf3-cd39-463f-b2ba-d0ce46c246bd","metadata":{"id":"12edbaf3-cd39-463f-b2ba-d0ce46c246bd"},"source":["# Predict One Sentence"]},{"cell_type":"code","execution_count":null,"id":"99bc3835-a075-4fce-812b-7b9e96778816","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"99bc3835-a075-4fce-812b-7b9e96778816","outputId":"5407a8ca-80c9-40b4-e7a6-1032e1530e74"},"outputs":[],"source":["def align_word_ids(texts):\n","  \n","    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n","\n","    word_ids = tokenized_inputs.word_ids()\n","\n","    previous_word_idx = None\n","    label_ids = []\n","\n","    for word_idx in word_ids:\n","\n","        if word_idx is None:\n","            label_ids.append(-100)\n","\n","        elif word_idx != previous_word_idx:\n","            try:\n","                label_ids.append(1)\n","            except:\n","                label_ids.append(-100)\n","        else:\n","            try:\n","                label_ids.append(1 if label_all_tokens else -100)\n","            except:\n","                label_ids.append(-100)\n","        previous_word_idx = word_idx\n","\n","    return label_ids\n","\n","\n","def evaluate_one_text(model, sentence):\n","\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    if use_cuda:\n","        model = model.cuda()\n","\n","    text = tokenizer(sentence, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n","\n","    mask = text['attention_mask'].to(device)\n","    input_id = text['input_ids'].to(device)\n","    label_ids = torch.Tensor(align_word_ids(sentence)).unsqueeze(0).to(device)\n","\n","    logits = model(input_id, mask, None)\n","    logits_clean = logits[0][label_ids != -100]\n","\n","    predictions = logits_clean.argmax(dim=1).tolist()\n","    prediction_label = [ids_to_labels[i] for i in predictions]\n","    print(sentence)\n","    print(prediction_label)\n","\n","evaluate_one_text(model, 'Newborn young measured from 2 to 20 mm in length')"]},{"cell_type":"code","execution_count":null,"id":"fa186d96-7e3c-4457-a3ab-cabc61f2d261","metadata":{"id":"fa186d96-7e3c-4457-a3ab-cabc61f2d261"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"723f31f2-12d7-48cc-9f88-1c8fbe860f4c","metadata":{"id":"723f31f2-12d7-48cc-9f88-1c8fbe860f4c"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.13 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"94e7e65be05b4ed6ba93e18d7d6886bab5ac9fc35747516c0d44d14f8ddf2d8d"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"2c10625508cf400cb355164e767a7c08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54d31286f3a0492985f32ded812ebaaa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7c6c693f9a814166afe11e6ded2fb72c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"832510fef8f04cd08eb3ae8af0676b79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c62a3ecb7ce467c950d677eee83d88a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7ce5cf15868435a839a852aa712cfc0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c6c693f9a814166afe11e6ded2fb72c","placeholder":"​","style":"IPY_MODEL_832510fef8f04cd08eb3ae8af0676b79","value":"Downloading: 100%"}},"ad05041418fc4162a6702edd9a1b1b52":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b34bdaf49c134d6596f6e6c53c612446":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b724bc96afae4aefbb7402ff4f393e66":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b34bdaf49c134d6596f6e6c53c612446","max":435779157,"min":0,"orientation":"horizontal","style":"IPY_MODEL_54d31286f3a0492985f32ded812ebaaa","value":435779157}},"ec294d37d6474e849d707ab4d6a366b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a7ce5cf15868435a839a852aa712cfc0","IPY_MODEL_b724bc96afae4aefbb7402ff4f393e66","IPY_MODEL_fbb4d7b182b64cfb9f0dcb011e15c42e"],"layout":"IPY_MODEL_9c62a3ecb7ce467c950d677eee83d88a"}},"fbb4d7b182b64cfb9f0dcb011e15c42e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad05041418fc4162a6702edd9a1b1b52","placeholder":"​","style":"IPY_MODEL_2c10625508cf400cb355164e767a7c08","value":" 436M/436M [00:10&lt;00:00, 52.2MB/s]"}}}}},"nbformat":4,"nbformat_minor":5}
